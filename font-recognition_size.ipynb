{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport os\nfrom typing_extensions import TypedDict\nfrom typing import Generator, List, NamedTuple, Iterable\nimport json\nimport cv2\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-11T03:32:27.5389Z","iopub.execute_input":"2022-02-11T03:32:27.539322Z","iopub.status.idle":"2022-02-11T03:32:27.814571Z","shell.execute_reply.started":"2022-02-11T03:32:27.539238Z","shell.execute_reply":"2022-02-11T03:32:27.813827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fff = pd.read_csv('../input/data-real-frame-123/Data_real_Frame_123.csv')\n\nl=[]\ndata_font=[]\nreal_train_size=[]\n\nfor i in range(len(fff['Image'])) :\n    b=fff['Image'][i]\n    b=b[1:-1].split(', ')\n    b=list(map(int,b))\n    b=[b]\n    b=np.array(b)\n    b=b.reshape(32,32,1)\n    l.append(b)\n    real_train_size.append(fff['size'][i])\n\nreal_train_img=np.array(l)\nreal_train_size=np.array(real_train_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:32:27.816024Z","iopub.execute_input":"2022-02-11T03:32:27.816256Z","iopub.status.idle":"2022-02-11T03:33:33.290752Z","shell.execute_reply.started":"2022-02-11T03:32:27.816222Z","shell.execute_reply":"2022-02-11T03:33:33.290041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport PIL\nimport matplotlib.pyplot\nimport os\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\ndef get_location(path_json,path_img):\n    #output_path = '/home/superai2-4031/Hackathon1/testcrop/' # \n    images=[]\n    image = cv2.imread(path_img)\n    j=open(path_json)\n    js=json.load(j)\n    for i in range(len(js)):\n        try:\n            parentId = (js[i]['id'])\n            x1 = round(js[i]['x'])\n            x2 = round(x1+js[i]['width'])\n            y1 = round(js[i]['y'])\n            y2 = round(y1+js[i]['height'])\n            img =np.array(image[y1:y2,x1:x2])\n            w,h=img.shape[0:2]\n            if w==h:  img\n            elif w>h: img= img[0:h , 0:h]\n            elif w<h: img= img[0:w , 0:w]\n            img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            img=cv2.resize(img,(32,32))\n            img=img[:,:,None]\n            images.append(img)\n        except:\n            img=np.zeros((32,32))\n            img=cv2.resize(img,(32,32))\n            img=img[:,:,None]\n            images.append(img)\n            \n    return images\ndef get_label(path_json):\n    parentId=[]\n    j=open(path_json)\n    js=json.load(j)\n    for i in range(len(js)):\n        parentId.append(js[i]['id'])\n    return parentId","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:33:33.292808Z","iopub.execute_input":"2022-02-11T03:33:33.293324Z","iopub.status.idle":"2022-02-11T03:33:37.413028Z","shell.execute_reply.started":"2022-02-11T03:33:33.293284Z","shell.execute_reply":"2022-02-11T03:33:37.412303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder=[]\nparentID=[]\nimage=[]\npath='../input/data-test2' # path test\npath_final_test='../input/super-ai-engineer-2021-font-recognition/final_test' # path test\ncsv=pd.read_csv('../input/sample/sample_submission.csv') #path subbission\ni=0\nfor folder in sorted(os.listdir(path)): #path test\n    path_img = path +'/'+ str(folder) +'/'+ 'image.png'\n    path_json= path +'/'+ str(folder) +'/'+ 'test.json'\n\n    parentId= get_label(path_json)\n\n    im=get_location(path_json,path_img)\n    image=image+im\n    parentID=parentID+parentId\n    \nfor folder in sorted(os.listdir(path_final_test)): #path test_final\n    path_img = path_final_test +'/'+ str(folder) +'/'+ 'image.png'\n    path_json= path_final_test +'/'+ str(folder) +'/'+ 'test.json'\n    parentId= get_label(path_json)\n    im=get_location(path_json,path_img)\n    image=image+im\n    parentID=parentID+parentId\n    \n    \nimage=np.array(image)\nparentID=np.array(parentID)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:33:37.414843Z","iopub.execute_input":"2022-02-11T03:33:37.415098Z","iopub.status.idle":"2022-02-11T03:34:46.795253Z","shell.execute_reply.started":"2022-02-11T03:33:37.415063Z","shell.execute_reply":"2022-02-11T03:34:46.794396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size_type = ('12px', '14px', '16px', '18px', '20px', '22px', '24px')\nsize_type_df = pd.DataFrame(size_type, columns=['Size_type'])\nsize_type_df","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:34:46.796535Z","iopub.execute_input":"2022-02-11T03:34:46.796866Z","iopub.status.idle":"2022-02-11T03:34:46.813344Z","shell.execute_reply.started":"2022-02-11T03:34:46.796829Z","shell.execute_reply":"2022-02-11T03:34:46.812536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder \n# creating instance of one-hot-encoder\nenc = OneHotEncoder(handle_unknown='ignore')\n# passing bridge-types-cat column (label encoded values of bridge_types)\n\n# enc_df = enc.fit_transform(family_type_df[['family_type']]).toarray()\nlabel_size_df = enc.fit_transform(np.array(real_train_size).reshape((-1,1))).toarray()\n\nlabel_size_df , len(label_size_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:34:46.814688Z","iopub.execute_input":"2022-02-11T03:34:46.814964Z","iopub.status.idle":"2022-02-11T03:34:47.39567Z","shell.execute_reply.started":"2022-02-11T03:34:46.814908Z","shell.execute_reply":"2022-02-11T03:34:47.394873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_size = enc.inverse_transform(label_size_df)\nindex_size , len(index_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:34:47.397011Z","iopub.execute_input":"2022-02-11T03:34:47.397259Z","iopub.status.idle":"2022-02-11T03:34:47.413602Z","shell.execute_reply.started":"2022-02-11T03:34:47.397224Z","shell.execute_reply":"2022-02-11T03:34:47.41297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(real_train_img, label_size_df, test_size=0.1, random_state=42)\nX_train.shape , X_test.shape , y_train.shape , y_test.shape , X_train.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:37:44.49005Z","iopub.execute_input":"2022-02-11T03:37:44.490595Z","iopub.status.idle":"2022-02-11T03:37:44.948723Z","shell.execute_reply.started":"2022-02-11T03:37:44.490558Z","shell.execute_reply":"2022-02-11T03:37:44.947873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input ,Conv2D, Dense, Flatten, GlobalAveragePooling2D, AveragePooling2D\nbatch_size_ = 64\nnumOfLabel = 7\nresnet=ResNet50(include_top=False, weights='imagenet')\nx_in = layers.Input(shape=(32, 32, 1))\nx = Conv2D(3, 1)(x_in)\nx=resnet(x)\nx=Flatten()(x)\nx = layers.Dense(1000, activation='relu')(x)\n#x = AveragePooling2D(pool_size=(7, 7))(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(256, activation=\"relu\")(x)\n#x = Dropout(0.5)(x)\nx = layers.Dense(7, activation='softmax')(x)\n\n\nmodel = Model(x_in, x)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\nmodel.summary()\nfor layer in model.layers:\n    layer.trainable = False\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices()) # list of DeviceAttributes\nsteps_per_epoch_ = X_train.shape[0] // batch_size_\nsteps_per_epoch_\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\ncallback_list = [early_stopping]\ncsv_logger = tf.keras.callbacks.CSVLogger('training.csv', append=True)\n#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\nhistory = model.fit(x=tf.squeeze(X_train), y=tf.squeeze(y_train)  ,validation_data = (X_test,y_test), steps_per_epoch = steps_per_epoch_, epochs = 100,callbacks=callback_list)\nmodel.save(\"model_size.h5\")\n\nfig, axes = plt.subplots(1, 2)\n\n# plot train and test accuracies\naxes[0].plot(history.history['accuracy']) # training accuracy\naxes[0].plot(history.history['val_accuracy']) # testing accuracy\naxes[0].legend(['Training', 'Testing'])\naxes[0].set_title('Accuracy Over Time')\naxes[0].set_xlabel('epoch')\naxes[0].set_ybound(0.0, 1.0)\n\n# same plot zoomed into [0.85, 1.00]\naxes[1].plot(history.history['loss']) # training accuracy\naxes[1].plot(history.history['val_loss']) # testing accuracy\naxes[1].legend(['Training', 'Testing'])\naxes[1].set_title('Log-Inverse Accuracy')\naxes[1].set_xlabel('epoch')\n#axes[1].set_ybound(0.90,1.0)\nplt.show()\n\nscore = model.evaluate(X_test,y_test, verbose=False)\nprint('Loss: {}'.format(score[0]))\nprint('Accuracy: {}%'.format(np.round(10000*score[1])/100))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T04:03:48.253372Z","iopub.execute_input":"2022-02-11T04:03:48.25363Z","iopub.status.idle":"2022-02-11T05:11:45.18635Z","shell.execute_reply.started":"2022-02-11T04:03:48.253599Z","shell.execute_reply":"2022-02-11T05:11:45.185629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size_ = 64\nimport os \nimport zipfile \nimport tensorflow as tf \nfrom tensorflow.keras import Model \nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.optimizers import gradient_descent_v2\nfrom tensorflow.python.keras.optimizer_v2.adam import Adam\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input ,Conv2D, Dense, Flatten, GlobalAveragePooling2D\nbatch_size_ = 64\nnumOfLabel = 7\nmodel =load_model('../input/model-size123/model_size.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:35:07.606153Z","iopub.execute_input":"2022-02-11T03:35:07.606414Z","iopub.status.idle":"2022-02-11T03:35:13.931924Z","shell.execute_reply.started":"2022-02-11T03:35:07.606383Z","shell.execute_reply":"2022-02-11T03:35:13.931183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = np.argmax(model.predict(image),axis=-1)\ny_class=[]\nfor i in Y_pred:\n    y_class.append(size_type[int(i)])\ndf=pd.DataFrame({'ID':parentID,'size':y_class})\ndf.to_csv('size_predicted.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T03:35:13.934192Z","iopub.execute_input":"2022-02-11T03:35:13.934427Z","iopub.status.idle":"2022-02-11T03:35:51.870733Z","shell.execute_reply.started":"2022-02-11T03:35:13.934391Z","shell.execute_reply":"2022-02-11T03:35:51.869991Z"},"trusted":true},"execution_count":null,"outputs":[]}]}